# Task1: Библиотека OpenMP

## Характеристики вычислительной машиины

- Процессор - AMD Ryzen 7 5800H 8 ядер/16 потоков(hyperthreading).
- Оперативная память - 2 * 8GiB 3200MHz.
- Операцилнная система Manjaro Linux, Kernel: 6.1.80-1-MANJARO.
- Версия gcc (GCC) 13.2.1. Версия OpenMP 4.5.

## Условия экспериментов

Замеры проводились для фунций run_parallel, run_sequential, которые выполняют непосредственно вычисление на готовой сетке.

### Эксперимент 1

Код запускался для апроксимации функции $u(x,y)$ на $[0;1]\times[0;1]$ , задаваемой уравнениями $u''_{x^2} + u''_{y^2} = f(x,y)$ и $u(x,y) = g(x,y)$ на границах области.

$f(x,y) = 0$

$g(x,y) = (1 - 2 * y) * (1 - 2 * x) * 100$

Все запуски проводились в 8 потоков. Эксперимент нацелен на опреление оптимального размера блока, который считается последовательно в параллельном алгоритме.

Программа компилировалась без оптимизации -O0 и с оптимизацией -O3.

Замеры проводились 10 раз для сеток размером 100, 500, 1000, 1500, 2000 и блока размером 1,  16, 32, 64, 128.

### Гипотеза 1

В алгоритме 11.6 используется идея разбить сетку на блоки и параллельно запускать последовательный алгоритм для нескольких блоков. Это делается для более эффективной работы кэша. Эксперемент проводится с целью определить оптимальный размер блока для конкретной вычислительной машины. Для данного эксперимента достаточно рассмотрения одной краевой задачи, т.к. выбор размера блока не связан с задачей. и будет работать одинаково для всех задач с решеткой фиксированного размера.

### Результаты

Результаты экспериментов представлены в [таблице для -O0](https://docs.google.com/spreadsheets/d/1SAL_Ha-3T_NXenxJnTDxKkMBuQNJpvU8olWJkgs7L6c/edit?hl=ru#gid=0)  и [таблице для -O3](https://docs.google.com/spreadsheets/d/1SAL_Ha-3T_NXenxJnTDxKkMBuQNJpvU8olWJkgs7L6c/edit?hl=ru#gid=1767930087). Можно заметить, что практически во всех случаях побеждают запуски с размером $32\times32$. Поэтому далее в следующих жкспериментах будем использовать такой размер блока.

### Эксперимент 2

Алгоритм запускался на сетках размером: 100, 500, 1000, 1500, 2000. Запускались последовательная версия и параллельная в 4, 8 и 16 потоков. Для каждого случая время и количество итераций(фиксированное для размера сетки) определялись как среднее арифметическое за 10 запусков. Также были проведены тесты с опцией компилятора -O0 и -O3.

### Гипотеза

Распараллеливая вычисления максимальное ускорение равно количеству потоков. Но при работе с несколькими потоками появляются накладные расходы, например для синхронизации или при работе с кэшами процессора. Кроме того, предполагаю, что hyperthreading не дает преимущества в данной задаче, так как технология работает за счёт того, что меняет порядок операций, которые задействуют разные юниты процессора. А наша задача предполагает исполнение однотипных операций. Кроме того у каждого ядра свой кэш, а если два потока работают на одном ядре с разными данными одновременно, то их надо будет перекидывать в кэшэ, что замедлит исполнение программы.

### Результаты

Результаты эксперимента представлены в [таблице](https://docs.google.com/spreadsheets/d/1U85Hm3oIyZ8q29F1JuFEv_nTrgeeJOjgP4pFWPJj0rs/edit?usp=sharing).

**Для случая без программы без оптимизации компилятора.**
Ускорение при распараллеливании возрастает при увеличении размера сетки. Максимальное зафиксированное ускорение достигается на сетке размером 2000 в 8 потоков и равно 4.37. Время выполнения в 16 потоков, как и предполагалось, немного проигрывает 8 потокам.

**Для случая без программы с оптимизацией компилятора.**
Максимальное ускорение достигается на сетке размером 1000 и при исполнении на 16 потоках и составляет 5.70.
