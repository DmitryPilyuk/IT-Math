# Task1: Библиотека OpenMP

## Характеристики вычислительной машиины

- Процессор - AMD Ryzen 7 5800H 8 ядер/16 потоков(hyperthreading).
- Оперативная память - 2 * 8GiB 3200MHz.
- Операцилнная система Manjaro Linux, Kernel: 6.1.80-1-MANJARO.
- Версия gcc (GCC) 13.2.1. Версия OpenMP 4.5.

## Условия экспериментов

Замеры проводились для фунций run_parallel, run_sequential, которые выполняют непосредственно вычисление на готовой сетке.

### Эксперимент 1

Код запускался для апроксимации функции $u(x,y)$ на $[0;1]\times[0;1]$ , задаваемой уравнениями $u''_{x^2} + u''_{y^2} = f(x,y)$ и $u(x,y) = g(x,y)$ на границах области.

$f(x,y) = 0$

$g(x,y) = (1 - 2 * y) * (1 - 2 * x) * 100$

Все запуски проводились в 8 потоков. Эксперимент нацелен на опреление оптимального размера блока, который считается последовательно в параллельном алгоритме.

Программа компилировалась без оптимизации -O0 и с оптимизацией -O3.

Замеры проводились 10 раз для сеток размером 100, 500, 1000, 1500, 2000 и блока размером 1,  16, 32, 64, 128.

### Гипотеза 1

В алгоритме 11.6 используется идея разбить сетку на блоки и параллельно запускать последовательный алгоритм для нескольких блоков. Это делается для более эффективной работы кеша. Эксперемент проводится с целью определить оптимальный размер блока для конкретной вычислительной машины. Для данного эксперимента достаточно рассмотрения одной краевой задачи, т.к. выбор размера блока не связан с задачей. и будет работать одинаково для всех задач с решеткой фиксированного размера.

### Результаты 1

Результаты экспериментов представлены в [таблице для -O0](https://docs.google.com/spreadsheets/d/1SAL_Ha-3T_NXenxJnTDxKkMBuQNJpvU8olWJkgs7L6c/edit?hl=ru#gid=0)  и [таблице для -O3](https://docs.google.com/spreadsheets/d/1SAL_Ha-3T_NXenxJnTDxKkMBuQNJpvU8olWJkgs7L6c/edit?hl=ru#gid=1767930087). Можно заметить, что практически во всех случаях побеждают запуски с размером $32\times32$. Поэтому далее в следующих экспериментах будем использовать такой размер блока.

### Эксперимент 2

Алгоритм запускался на сетках размером: 100, 500, 1000, 1500, 2000 для задачи упомянутой выше. Запускались последовательная версия и параллельная в 4, 8 и 16 потоков. Для каждого случая время и количество итераций(фиксированное для размера сетки) проводилось 10 замеров. Также были проведены тесты с опцией компилятора -O0 и -O3.

### Гипотеза

Распараллеливая вычисления максимальное ускорение равно количеству потоков. Но при работе с несколькими потоками появляются накладные расходы, например для синхронизации или при работе с кешами процессора. Также, предполагаю, что hyperthreading не дает значимого преимущества в данной задаче, так как технология работает за счёт того, что меняет порядок операций, которые задействуют разные юниты процессора. А наша задача предполагает исполнение однотипных операций. Кроме того у каждого ядра свой кеш, а если два потока работают на одном ядре с разными данными одновременно, то их надо будет перекидывать в кешэ, что замедлит исполнение программы.

### Результаты

Результаты эксперимента представлены в [таблице для -O0](https://docs.google.com/spreadsheets/d/1U85Hm3oIyZ8q29F1JuFEv_nTrgeeJOjgP4pFWPJj0rs/edit#gid=1944427654) и [таблице для -O3](https://docs.google.com/spreadsheets/d/1U85Hm3oIyZ8q29F1JuFEv_nTrgeeJOjgP4pFWPJj0rs/edit#gid=1087232279).

**Для случая без программы без оптимизации компилятора.**
На сетке размером $100\times100 все алгоритмы работают за примерно одинаковое время, алгоритмы в 4 и 8 потоков дают небольшой выигрыш, а запуск в 16 потоков несильно проигрывает последовательному алгоритму. При увеличении размеров сетки максимальное ускорение относительно последовательного алгоритма достигается на сетке $1500\times1500$ при исполнении в 16 потоков и составляет 4.96 раз. И в целом исполнение в 16 потоков в среднем быстрее чем в 8. Во-первых это может быть связано с тем, что исполнение в 8 потоков тоже использует гипертрединг, а не испоняет каждый поток на отдельном ядре. Так же все-таки стоить заметить, что разница при запусках в 8 и 16 потоков мала, что частично подтверждает гипотезу, т.к. при увеличении количества потоков в 2 раза, то есть потенциально программа может выполнятся быстрее последовательного алгоритма в 16 раз, получаем незначительное ускорение случая в 8 потоков.

**Для случая без программы с оптимизацией компилятора.**
При использовании оптимизации на сетке $100\times100$ наблюдаем похожие значения для всех запусков, параллельные алгоритмы в 4 и 8 потоков не дают сильного выигрыша всего в 1.3 - 1.4 раза. А параллельный алгоритм в 16 потоков проигрывает почти в 5 раз параллельному. На сетках $500\times500$ и $1000\times1000$ наблюдается наибольшее ускорение в 8 потоков(16 потоков) 4.476(4.588) и 5.583(6.267) соответственно. При увеличении сетки запуски в 8 потоков показывают лучшие результаты чем в 16 потоков. Но ускорение не такое значительное, как на сетказ $500\times500$ и $1000\times1000$. Вероятно это связвно с выбранным размером блока и какими-то специфичными оптимизациями, например, раскручивание циклов.
